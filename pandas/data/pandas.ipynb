{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1efff9b97a9e667766635263e01fd053",
     "grade": false,
     "grade_id": "cell-4ee60680d699ca5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Pandas\n",
    "\n",
    "## Introduction\n",
    "\n",
    "When processing data, you will most often work with _structured data_. This is the kind of data where you have a table with some number of named columns, each corresponding to a different feature, and a sequence of rows, each corresponding to a different sample. Examples of structured data can be found everywhere and occur any time you are making a series of observations and write down some properties for each observation you make.\n",
    "\n",
    "Some examples of structured data are:\n",
    "- Weather reports, where you have columns such as 'Date', 'Temperature' and 'Humidity', and each row shows the temperature and humidity on some date.\n",
    "- Companies use structured data everywhere, from user accounts to product information and from purchases to reviews.\n",
    "- A grocery list is a very simple type of structured data, where you have a 'Product' and 'Amount' column indicating how many of what product you intend to buy.\n",
    "\n",
    "_Note on notation:_ There are many different ways to refer to the columns and rows in a table. This notebook will refer to the vertically orientated axis as 'columns' (but elsewhere this might be called a 'field', 'feature' or 'property') and the horizontal axis as 'rows' (also called 'entries', 'samples' or 'observations').\n",
    "\n",
    "`Pandas` (often imported as `pd`) is the most popular library to use when dealing with structured data in Python. In this exercise notebook, we will explore some of the basics of working with Pandas. This notebook will not be able to cover everything you will ever need, but will hopefully give you an idea of what it can do for you. \n",
    "\n",
    "Some sections will end with a note on *Further Reading*; this will not be necessary for completing the exercises, but references relevant information that might help you in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29a4ddf03c5da61b0126076060ce76e2",
     "grade": false,
     "grade_id": "cell-28dfb4e4ca3dd630",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tests import *\n",
    "\n",
    "# This line indicates that any floating point number should only have 2 digits\n",
    "# past the decimal point. This prevents numbers like 5.00000003 to be printed,\n",
    "# and instead will just print 5.00.\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3cf464c9c136c1c51a0778b70b233298",
     "grade": false,
     "grade_id": "cell-20f1b458782aec6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## DataFrames\n",
    "\n",
    "Structured data is nothing more than a table consisting of rows and columns. In `Pandas`, such a table is called a `DataFrame`. To create a DataFrame called `df`, you can use `df = pd.DataFrame(data)` where `data` is a `list` of rows, and each row is also a list, containing the values for that row. Below you can see a simple example of creating a table with 2 rows and 3 columns.\n",
    "\n",
    "You can have any number of rows, but it is important that each row has the same number of elements (i.e. columns), otherwise you will get an error. The example below uses Jupyter's `display` function to get a nice looking output (although `print` also works)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2963c5591e923691b19384efb7099458",
     "grade": false,
     "grade_id": "cell-cc86c6bcba27183e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = [[1, 2, 3], # The first row has values 1, 2, 3\n",
    "        [4, 5, 6]] # The second row has values 4, 5, 6\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "80e33440936e85bf85ea7a263b7598b5",
     "grade": false,
     "grade_id": "cell-b13c4fe8e8b5182e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now this is not a very descriptive table, since the columns are just called `0`, `1` and `2`. To change this, you can use the optional `columns` argument when creating the `DataFrame`, where you can specify the names of each of the columns using a `list`. Make sure to provide as many column names as there are columns in your data (the number of values in a single row), otherwise you will get an error.\n",
    "\n",
    "Let's create another dataframe; the first column has values `'a'` and `'b'` and we call it `'Some letter'`, another column with values `2` and `5` we call `'Int'` and finally a column with `3.5` and `6.5` we call `'A float'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "319b254b722da3433357b9cd9ed9c037",
     "grade": false,
     "grade_id": "cell-cec7ba37bc00f1e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = [['a', 2, 3.5],\n",
    "        ['b', 5, 6.2]]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Some letter', 'Int', 'A float'])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3fc328988fa4e67d401f4eaad178158",
     "grade": false,
     "grade_id": "cell-0e7161087ca2e7ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You might have already noticed that each of the _rows_ also gets its own index on the left (in this case it is `0` and `1`, which it does by default). This is called the `index` of the dataframe (which you can see by using `df.index`), and can be set using the optional `index` argument to provide a `list` of row names when creating the `DataFrame`.\n",
    "\n",
    "Again, make sure you provide as many names in the `index` argument as there are rows (in this case 2 rows, and therefore 2 names); otherwise you will get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b91fc6b3944002431c6b8446bc7ff3af",
     "grade": false,
     "grade_id": "cell-88a63bcb69a1ece3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = [['a', 2, 3.5],\n",
    "        ['b', 5, 6.2]]\n",
    "\n",
    "df = pd.DataFrame(data,\n",
    "    index=['First Row', 'Row 2'],\n",
    "    columns=['Some letter', 'Int', 'A float']\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7731f72b2de163517367640ad31dfe34",
     "grade": false,
     "grade_id": "cell-f53022f82a21d123",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"The index column of the dataframe:\")\n",
    "display(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f08009c9f0bb81aa166248de9e8d354",
     "grade": false,
     "grade_id": "cell-fd8aa5592f49fa25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1\n",
    "Create a DataFrame called `df` that contains the data in the following table:\n",
    "\n",
    "|       | **A** | **B** |\n",
    "|-------|-------|-------|\n",
    "| **X** | 5.3   | foo   |\n",
    "| **Y** | 2.0   | bar   |\n",
    "| **Z** | 0.2   | baz   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f946a6780d813f6d5c7bdd08fb735994",
     "grade": false,
     "grade_id": "cell-2d40200d14268af9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6416439831987fbc962a5e70687b0aba",
     "grade": true,
     "grade_id": "cell-5babe7262dd631ff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47c27f1f968ec5bc5a6dd9c9ac66ed12",
     "grade": false,
     "grade_id": "cell-823343eacba0e5cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Further Reading:* You can find the full documentation on creating a DataFrame [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame) (which lists the technical description of all the options) or use the Pandas User Guide [on DataFrames](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#basics-dataframe) (which includes more examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08dd22f148736e31a2430c37e5e51e97",
     "grade": false,
     "grade_id": "cell-1f8d4839e8f944d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we know how to create a DataFrame, let's see what we can do with them!\n",
    "\n",
    "This notebook will follow a narrative where you are hired as the new head of (and only member of) the Data Processing department of your local grocery store. This grocery store has kept a record of their products, and it is now up to you to process this data. This record consists of products, to what category they belong, their price, the size (i.e. 'unit') of the product and the current stock.\n",
    "\n",
    "We have provided you with a function `get_df()` which gets you the data as a `DataFrame` for you to use. As you can see, it is _indexed_ on the 'Product' and has the _columns_ 'Category', 'Price', 'Unit' and 'Stock'. The example `DataFrame` is displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48855965d9b2ba65125a606e2761ea35",
     "grade": false,
     "grade_id": "cell-0e8aa4042c01fe9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a574ca105d9283c735d9d1fd7b6b2d0f",
     "grade": false,
     "grade_id": "cell-18ae40ebdd324183",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Getting data from a DataFrame\n",
    "\n",
    "A table consists of columns with values for each row; and similarly, a `DataFrame` consists of `Series` with values for each index. Therefore, if you want to look at a single column of your data, you'll need to retrieve that `Series` from your `DataFrame`!\n",
    "\n",
    "To see what columns are in your DataFrame, you can use the `df.columns` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c0f0beaf6fdd0f8e87b82a91d801384",
     "grade": false,
     "grade_id": "cell-e00dbc7a60427561",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"The columns of `df`:\")\n",
    "display(df.columns)\n",
    "\n",
    "# Indexing works the same way as a list:\n",
    "print(\"\\nThe second column is:\", df.columns[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cfef9982283e3cc1ed5b69ed903c83ec",
     "grade": false,
     "grade_id": "cell-791613bd0723b078",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To get a column from your DataFrame, you can index it in the same way you do with a dictionary: by using `df['ColumnName']`, where `df` is your DataFrame and `ColumnName` is the name of your column. The code below retrieves the 'Price' column from our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da409647b20f45ac549a139823ee76cb",
     "grade": false,
     "grade_id": "cell-aab348fdbcc33479",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the 'Price' column from the DataFrame as a Series\n",
    "prices = df['Price']\n",
    "\n",
    "display(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50e10f885e577c92d89bed7ca5be9922",
     "grade": false,
     "grade_id": "cell-7e2d235c36fdb065",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here you can see that this is indeed a 'Series' object:\n",
    "print(\"The variable 'prices' is of type:\", type(prices))\n",
    "\n",
    "# You can always check the dtype of your Series by using .dtype:\n",
    "print(\"This Series has dtype:\", prices.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8045df0efd3f15ae77d4be0458109c64",
     "grade": false,
     "grade_id": "cell-9f924463c153d463",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the example above you can see that this Series doesn't just contain the _values_ of the 'Price' column (displayed on the right), but also the _index_, which lists the product names from the original DataFrame (displayed on the left). This way, it is a lot easier to see which price belongs to what product! Lastly, you can see at the bottom what the `dtype` of this column is (in this case `float64`, since these are floating point numbers).\n",
    "\n",
    "Accessing the data in that `Series` then also works in the same way as for dictionaries: you can just use the index as the key. For example, the price of Broccoli can be found by first retrieving the 'Price' column from the `DataFrame`, and then indexing the resulting `Series` on 'Broccoli':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8d08d666201500d2e2e05d97fecd8b0",
     "grade": false,
     "grade_id": "cell-f86745dd66eaef99",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the 'Price' column from the DataFrame as a Series\n",
    "prices = df['Price']\n",
    "\n",
    "# Get the 'Broccoli' value from that Series\n",
    "price_broccoli = prices['Broccoli']\n",
    "\n",
    "print(\"The price of Broccoli is:\", price_broccoli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00b2d6eb2ae772dbde9f27c99fd01bad",
     "grade": false,
     "grade_id": "cell-d72fafd04997cc7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "In the 'Stock' column, how many 'Penne' are left? Use `df` to find the value and save the result in `stock_penne`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d53756f3b0898f3e85b021e2bd21877",
     "grade": true,
     "grade_id": "cell-8b6ac6cf5d75165c",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "stock_penne = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"There are\", stock_penne, \"penne in stock.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a297a19ac9cc06816d70fa37d7674dfe",
     "grade": false,
     "grade_id": "cell-45cb8a2ef0035c44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Series\n",
    "\n",
    "A `Series` is data structure specific to *Pandas*, that has aspects of both lists and dictionaries. It is like a `list` in that it is an ordered sequence of data, meaning it just stores different values together in some order. However, the indices used for a `Series` don't need to be the integers $0, 1, \\dots$, like with a list, but can be any type, including strings, like the keys of a `dictionary`.\n",
    "\n",
    "Note that all the values in a `Series`, must be of the same type, like with *Numpy* `ndarrays`. In the example above, the `Series` has a `dtype` of float, meaning it can only contain floating point values. Lastly, a `Series` has an optional name, which is set automatically here to the name of the column from the `DataFrame` where it came from.\n",
    "\n",
    "If we want to create a `Series`, we can just define it using a list of indices and list of values. Note that order here matters; position 0 in the index list will become the index for position 0 in the value list, and this will become the first element in the `Series`. Below is an example to create a `pd.Series` called `discount` with products as its indices and a discounted price as its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "caae0be1c1a7405721ccc1d3545714c8",
     "grade": false,
     "grade_id": "cell-cec0ad8985439a6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "discount_products = ['Strawberry', 'Apple', 'Coffee', 'Juice', 'Broccoli']\n",
    "discount_prices = [2.99, 2.15, 4.99, 1.89, 0.99]\n",
    "\n",
    "discount = pd.Series(\n",
    "    data=discount_prices,      # Use discount_prices as the values\n",
    "    index=discount_products,   # Use discount_products as the index\n",
    "    dtype=float,               # Set the type for the `data` argument to floating point numbers\n",
    "    name=\"Discount\",           # Set the name for the Series to Discount\n",
    ")\n",
    "\n",
    "display(discount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9be6b7a3a4573dadaccf26e36fb39680",
     "grade": false,
     "grade_id": "cell-c4749cd987b7236c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The most basic version of a `Series` is just a sequence of data of the same type, meaning you actually don't _need_ to provide an index for your `Series`. If you do not provide any index, `Pandas` will just use $0, 1, \\dots$, like the indices of a `list`.\n",
    "\n",
    "However, much of the power of Pandas is the use of this index to easily retrieve rows from your DataFrame (more on this in the section on [Indexing, Selection and Masking](#indexing-selection-and-masking)). It is therefore always recommended to use _some_ sort of index for your Series, if you can!\n",
    "\n",
    "Below is an example of the basic way you can create a Series, by just providing a `list` of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e3b9ddc9441bcb4296e530acb97ca5d",
     "grade": false,
     "grade_id": "cell-fef727754f7e3266",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "basicSeries = pd.Series([6.4, 2.3, 1.0])\n",
    "\n",
    "display(basicSeries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2edc9031913e86bfcafa50b88c75e4b6",
     "grade": false,
     "grade_id": "cell-ca21be2cf08156a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can create a `Series` with any kind of data. Below are some more examples with different data types: pay attention to the resulting `dtype` for each!\n",
    "\n",
    "Pandas tries its best to find the right type for your Series, and falls back on an `object` type if it cannot find a type that works. A Series must always be consistent in its type for all values in the Series, and standard types for this are the same as for *Numpy*; integers, floats and booleans. Note that *strings* are not in this list, and so strings also get the generic `object` type.\n",
    "\n",
    "What you can do with a column largely depends on the `dtype` of that `Series`, so always try to pick the type that works for your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3d729f43e05b449aeac050f8193c5f5",
     "grade": false,
     "grade_id": "cell-b74a9622b2eda844",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"A Series with strings gets dtype 'object':\")\n",
    "display(pd.Series(['a', 'b', 'c']))\n",
    "\n",
    "print(\"\\nIf you provide a mix of integers and floats, it will convert all elements to floats:\")\n",
    "display(pd.Series([1, 2, 3.0]))\n",
    "\n",
    "print(\"\\nBut you can also force it to be a specific type:\")\n",
    "display(pd.Series([1, 2, 3.0], dtype=int))\n",
    "\n",
    "print(\"\\nIf you provide a mix of strings and other types, then everything becomes 'object's:\")\n",
    "display(pd.Series(['hello', 2, 3.0]))\n",
    "\n",
    "print(\"\\nAs a very useful extra, Pandas can even convert your date to a consistent type:\")\n",
    "display(pd.Series([ \"2023 aug 02\", \"2021 8 23\", \"1970/01/01\"], dtype=\"datetime64[ns]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e3f83c65c66d391a0c5a50dd66cf04b",
     "grade": false,
     "grade_id": "cell-88b450fedff4ddd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "At the end of the day, the following sales come in:\n",
    "\n",
    "|            |   |\n",
    "|------------|---|\n",
    "| Lettuce    | 1 |\n",
    "| Carrot     | 3 |\n",
    "| Spaghetti  | 1 | \n",
    "| Coffee     | 2 |\n",
    "| Apple      | 1 |\n",
    "| Strawberry | 1 |\n",
    "\n",
    "Create a `Series` called `sales` containing the data in the table above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0fdf6fc0f3fe84e6f2c65485ff9519db",
     "grade": true,
     "grade_id": "cell-0c4ba43cc5ed357d",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sales = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "display(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf2d4cd7d8009746a50c27feefca7965",
     "grade": false,
     "grade_id": "cell-96f5fc477eebb538",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Adding and modifying data\n",
    "\n",
    "You can *add* a column to your `DataFrame` in the same way we retrieved a column from the DataFrame before. If you have a Series called `mySeries`, you can add it to your DataFrame `myDataFrame` as a column named `'myColumn'` using `myDataFrame['myColumn'] = mySeries`. Pandas will even match the `index` of your Series and DataFrame, so all values end up in the right place!\n",
    "\n",
    "Let's use the `discount` Series from before and add it to the Dataframe. This will match all the indices in the Series with the DataFrame indices, and add the values in the right place. When there is no discount for a specific product, the value automatically gets set to `NaN`. We will come back to the different ways you can deal with the `NaN`s later, in the section on [Handling missing values](#Handling-missing-values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a0b2b3dfcc1ec9393d966b07d9cfa1b",
     "grade": false,
     "grade_id": "cell-6ae19980ded89724",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "print(\"The discount Series\")\n",
    "discount = pd.Series(discount_prices, index=discount_products)\n",
    "display(discount)\n",
    "\n",
    "print(\"Added to the DataFrame:\")\n",
    "df['Discount'] = discount\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d6efd396db106edec453f57319d06864",
     "grade": false,
     "grade_id": "cell-9289384f03d0c04a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can also easily modify values in `Series` using basic arithmetic operations. All arithmetic operations are element-wise by default, and broadcasted when necessary, exactly like in *Numpy*.\n",
    "\n",
    "Below is a simple example where we get a new inventory shipment with 10 items for each product, and need to update the DataFrame accordingly. Note that this increase is getting broadcasted to every value in the `Series` here.\n",
    "\n",
    "It is important to remember that any arithmetic operation always creates a **new** `Series`, and so doesn't modify the existing DataFrame! If we want to update the values in the DataFrame, we need to re-assign the new Series to the corresponding collumn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "453c04d5e6488ddb1d6180ce43373282",
     "grade": false,
     "grade_id": "cell-985438385aa8647a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Adding 10 to the stock of every product:\")\n",
    "increased_stock = df['Stock'] + 10\n",
    "display(increased_stock)\n",
    "\n",
    "print(\"\\nReplacing the stock column in the DataFrame:\")\n",
    "df['Stock'] = increased_stock\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e2035208782c937bd9be1360b72f643",
     "grade": false,
     "grade_id": "cell-cdff78bb277b9470",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "An important difference with *Numpy* is that element-wise operations are always matched by *their index*, so the order of the elements in the Series actually does not matter, only what their index is. We'll come back to this in more detail in the section [Operating on DataFrames](#Operating-on-DataFrames), but for now we'll just give another example, so you have a bit of an idea of the possibilities:\n",
    "\n",
    "Let say you want to now compute the percentage of discount for each of the discounted prices, so you can use those to advertise your sale. First we'll need to compute ratio of the discounted prices compared to the original price and store the result in a new `Series`. We can just do this by dividing the Discount column by the Price column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b7dc527dae309d9983e24b1b7adcf76",
     "grade": false,
     "grade_id": "cell-ef4a91081e4efff3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "discount_ratio = df['Discount'] / df['Price']\n",
    "\n",
    "print(\"The ratio of the discounted price compared to the original price:\")\n",
    "display(discount_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1cd2782fa7864f89ae3d488d95ed210f",
     "grade": false,
     "grade_id": "cell-0e2e6c7973f8b7ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that this division was indeed performed element by element and matched on the index, so the discounted price of an apple was divided by the original price of an apple, and so on. The products that had a `NaN` value for the discount, then also automatically become `NaN` for the ratio.\n",
    "\n",
    "Next, we can just multiply this by $100$ to get a percentage, and subtract that value from $100$ to get the percentage that was discounted. Lastly, we can then add this new `Series` back into the `DataFrame` as a new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18df6171c4d55e4be8e45d932f216a88",
     "grade": false,
     "grade_id": "cell-3094cde7ea4caec5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "discount_percentage = 100 - discount_ratio * 100\n",
    "df['Percentage'] = discount_percentage\n",
    "\n",
    "print('Discount percentage added to the DataFrame:')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b70f4fb70ffdf47292c89feeb9499a03",
     "grade": false,
     "grade_id": "cell-aba3bc1eb4c329aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the `DataFrame` we can now see the apples have $10\\%$ discount when sold for $2.15$ instead of $2.39$, but we might want to advertise with the $33\\%$ discount on coffee instead!\n",
    "\n",
    "With a couple of discounts this is easy to spot, but for a larger `DataFrame` you would use built-in *aggregate* functions instead. Aggregate functions combine data in a column in some way, so for example using a `.sum()` to compute the total for a column. Here we'll need to use the `.max()` function to find the largest discount percentage and `.idxmax()` to find the product that largest discount belongs to. Note that `NaN` values in the Percentage column will just be ignored here, as this is the default behaviour for all aggregation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee47d6ddadfe7341312b074b8f4111aa",
     "grade": false,
     "grade_id": "cell-f1ef3d6ffa5e4954",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "largest_discount_percentage = df['Percentage'].max()\n",
    "largest_discount_product = df['Percentage'].idxmax()\n",
    "\n",
    "original_price = df['Price'][largest_discount_product]\n",
    "discount_price = df['Discount'][largest_discount_product]\n",
    "product_unit =  df['Unit'][largest_discount_product]\n",
    "\n",
    "print(f'Our best deal is a {int(largest_discount_percentage)}% discount on {largest_discount_product}:')\n",
    "print(f'Usually {original_price} per {product_unit}, but now on sale for {discount_price}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0b12a680ce03b2391b979d44a74fbb6",
     "grade": false,
     "grade_id": "cell-97ee3e221b5e887f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "In exercise 3 we created a `sales` Series with the amount sold, and the prices of each product are listed in the product DataFrame, so we can now see how much revenue we made from these products!\n",
    "\n",
    "Create a new Series called `revenue`, which combines the number of items sold from `sales` Series with prices from the product DataFrame `df`. The resulting Series should indicate the revenue per product and be added to the DataFrame as a column called Revenue. Finally, compute the total revenue by aggregating all the values in the `revenue` Series and store this as `total_revenue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66bffefa8ee939c8e966769a8b1ab1d4",
     "grade": false,
     "grade_id": "cell-144cc56c52d38286",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"As a quick reminder, this is the data in the sales Series:\")\n",
    "display(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "208479363f85deef6ee12fae439bec7f",
     "grade": false,
     "grade_id": "cell-7de1e59a8a3c8875",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Reset the DataFrame\n",
    "df = get_df()\n",
    "\n",
    "revenue = None\n",
    "total_revenue = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"Revenue per item, added as new column in the DataFrame:\")\n",
    "display(df)\n",
    "\n",
    "print(f\"\\n\\nIn total, the market had a revenue of: ${total_revenue:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "278c5ba551650a9a83f2e933f745f21a",
     "grade": true,
     "grade_id": "cell-d46b96bd60a352fb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_4(revenue, total_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4860b728d9655e2fc30ce74b9d20aa5",
     "grade": false,
     "grade_id": "cell-53a6950ceeb030e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Further Reading:* The official documentation has more about [creating a Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series). Pandas User Guide also has a [section on Series](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#basics-series) and the [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/03.01-introducing-pandas-objects.html) introduces Pandas using Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "744725e31c8ebdf15a03698c9cf05352",
     "grade": false,
     "grade_id": "cell-73d9958a5c31b093",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Indexing, Selection and Masking\n",
    "\n",
    "In the previous section we covered the most basic ways to retrieve data from a `DataFrame`, but there are many more ways to get data from a `DataFrame` in *Pandas*. As we've already covered how to retrieve columns, next we'll take a look at how to get specific rows from a `DataFrame`.\n",
    "\n",
    "The first thing we need to answer is: What is a 'row' in *Pandas*? Turns out: it's also a `Series`! That's great, because we just learned how to work with those. Let's start by taking another look at our example `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c46e3f607a967af82f78c90236a658b",
     "grade": false,
     "grade_id": "cell-f453fa6c590e3f79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c3bcc0ff510dce83e0399ca75dd8e40",
     "grade": false,
     "grade_id": "cell-e78dab19c393ff3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "There are several ways to access the rows in a `DataFrame`, but the most common ones are `df.loc[...]` and `df.iloc[...]`. These two methods look and work very similarly, but there are some important differences:\n",
    "\n",
    "### Using `df.loc[...]`\n",
    "\n",
    "The `.loc` property retrieves rows by making use of the *index* we defined for our dataframe. This works similarly to a dictionary, where you can use the key (i.e. index) to get the row you want: `df.loc['Banana']` will get you the row where the index is equal to 'Banana'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8233e427ddab1c744c0e344d49637f1c",
     "grade": false,
     "grade_id": "cell-02fb6bce8ad31874",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "row = df.loc['Banana']\n",
    "\n",
    "print(\"The row with index 'Banana' is:\")\n",
    "display(row)\n",
    "print(\"\\nThis row is of the type:\", type(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "308b8ef67b6ba24050daa9c853368ce9",
     "grade": false,
     "grade_id": "cell-af449366e0986729",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see, the resulting row `Series` automatically becomes indexed by the *columns* from the original DataFrame. This means that, for example, you could now retrieve the 'Price' for a specific `row` using `row['Price']`. This works the same way for any row, regardless of whether you're using either `.loc` or `.iloc` to retrieve it.\n",
    "\n",
    "### Using `df.iloc[...]`\n",
    "\n",
    "The `.iloc` property retrieves rows by the order in which the rows are stored in the `DataFrame`. It stands for \"integer location\" and works the same way as `list` indices: `df.iloc[0]` is the first row, `df.iloc[1]` is the second, et cetera.\n",
    "\n",
    "It is important to note that if you re-order your dataframe (such as with sorting), the order of the rows will change and therefore also their \"Integer location\"! After some operations, using `df.iloc[0]` might give a different result than before. This is different then with `df.loc`, where you just get the row matching the index regardless of the exact position in the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d9ce5a84813dae5ccd274796489cd51",
     "grade": false,
     "grade_id": "cell-80ac8127cd74db66",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "row = df.iloc[0]\n",
    "\n",
    "print(\"The first row of the DataFrame is:\")\n",
    "display(row)\n",
    "print(\"\\nThis row is of the type:\", type(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e387c8833a5afbf3c83cd20b55e0c49",
     "grade": false,
     "grade_id": "cell-26d5bbe4560ddd06",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Rows vs. columns\n",
    "\n",
    "Retrieving specific rows from a `DataFrame` can obviously be very useful, but there is an important caveat to keep in mind when working with rows:\n",
    "\n",
    "The problem here stems from the fact that a `Series` can only ever have one type. This works great for columns, as you expect a column of data to all be of the same type (e.g. a price column should always contain floats for each row). This is probably also the best way to look at what a `DataFrame` actually is: A collection of different columns of data, each with their *own data type*, that also each share the *same row index*.\n",
    "\n",
    "However, a single row of data will contain information from all of the different columns, which might have different types. For mixed types, *Pandas* will again try its best to convert the types to a consistent option, but if you have just one column with strings, then the whole row `Series` will become type 'object'. You can actually already see this happening in both the examples above!\n",
    "\n",
    "Converting everything to 'object' type means you lose the type information from the columns. In addition, these rows are actually *new* `Series` that have to be built by retrieving the values from each column for an index, and then combining them together into that `Series` (which is when the type conversion happens). This *much* slower than getting a column, where you simply can simply retrieve the stored `Series` from a `DataFrame`.\n",
    "\n",
    "As a result, the best option is usually to work with columns directly. Looping over the rows in a `DataFrame` might seem like a natural way to process data, as you're going through the data line by line, but this is actually very inefficient. Instead you should try and use element-wise operations to modify a whole column in a `DataFrame`, like the examples you've already seen in the section [Adding and modifying data](#Adding-and-modifying-data).\n",
    "\n",
    "Note that is still possible to loop through the rows of a `DataFrame` using functions like [`.iterrows()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iterrows.html). This function will create a new `Series` for each row and return them one by one, which can sometimes be very useful. However, if you do find yourself using this, ask yourself first if there isn't a better way to solve your problem, as this type of approach should always be one of the last options you try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f32d42e486af83e6a2ace2eab1597c4",
     "grade": false,
     "grade_id": "cell-b058beb634923da9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "Select the fifth row from `df` using the `.iloc[...]` property and store it it in the variable `fifth`.\n",
    "\n",
    "Next, select the row about Lettuce from `df` and save it in the variable `lettuce` using the `.loc[..]` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "560655dc5a4ae3d939d6832d2f58023f",
     "grade": true,
     "grade_id": "cell-2e9b82447ce4a3bc",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "fifth = None\n",
    "lettuce = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"Fifth row:\")\n",
    "display(fifth)\n",
    "\n",
    "print(\"Lettuce:\")\n",
    "display(lettuce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ecc7923ecd18646c4ebd30382ccba206",
     "grade": false,
     "grade_id": "cell-138648e9b84109cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Selecting multiple rows or columns\n",
    "\n",
    "In addition to using `.loc['Banana']` or `.iloc[8]` to obtain a single row, you can also pass a `list` of values to obtain multiple rows from your DataFrame in one go! This actually also works for *columns*, by passing a list of column names when indexing the DataFrame. Note that all these operations will *always* return a `DataFrame`, and not a `Series` like before - even if it is a `DataFrame` with only a single row or column!\n",
    "\n",
    "Below are some examples using lists to index a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71e8244fdac4f723205b639996ddfff5",
     "grade": false,
     "grade_id": "cell-a2289e48d1a2edb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "print(\"The full dataframe:\")\n",
    "display(df)\n",
    "\n",
    "rows1 = df.loc[ ['Carrot', 'Juice', 'Rice'] ]\n",
    "print(\"\\nThe rows with index 'Carrot', 'Juice' and 'Rice':\")\n",
    "display(rows1)\n",
    "\n",
    "rows2 = df.loc[ ['Carrot'] ]\n",
    "print(\"\\nThe row with index 'Carrot', as a DataFrame:\")\n",
    "display(rows2)\n",
    "\n",
    "rows3 = df.iloc[ [0, 2, 4] ]\n",
    "print(\"\\nFirst, third and fifth row, using a list of indices for iloc:\")\n",
    "display(rows3)\n",
    "\n",
    "rows4 = df[ ['Category', 'Price'] ]\n",
    "print(\"\\nSelecting only the Category and Price columns\")\n",
    "display(rows4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83b368936d20e7d7bcd49e0b578cd21c",
     "grade": false,
     "grade_id": "cell-ffa395a1314d4bd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The `df.iloc` property works with the position index, and also supports 'slices':\n",
    "- `df.iloc[a:]` returns everything starting from the `a`-th row.\n",
    "- `df.iloc[:b]` returns everything up to (but not including) the `b`-th row.\n",
    "- `df.iloc[::c]` returns every `c`-th row, starting with the first.\n",
    "    You can also think of this as the 'step size' with which to go through the DataFrame. By default this is 1, which is just every row. A step size of 2 means you skip every second row, et cetera.\n",
    "\n",
    "And these can also be combined as `df.iloc[a:b:c]` which says: from the `a`th to the `b`th row, give every `c`th row starting with the `a`th.\n",
    "\n",
    "*Further Reading:* You can find more examples on slices [here](https://www.geeksforgeeks.org/python-list-slicing/).\n",
    "\n",
    "Below are some examples. Feel free to try out some different values in a new cell, and predict what you'll see before running the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a03e0b839e0d8aa29d3a96d886acad8f",
     "grade": false,
     "grade_id": "cell-99d9f42e22ef8f65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "print(\"Full DataFrame, with a new default range as index:\")\n",
    "# If you reset the index, it will use indices 0,1,... instead\n",
    "# This will help see what integer indexes are for each row!\n",
    "display(df.reset_index())\n",
    "\n",
    "print(\"\\n\\nStarting at the tenth row:\")\n",
    "display(df.iloc[10:])\n",
    "\n",
    "print(\"\\n\\nFirst five rows:\")\n",
    "display(df.iloc[:5])\n",
    "\n",
    "# A negative index means: count backwards from the end\n",
    "print(\"\\n\\nStarting at the second-to-last row:\")\n",
    "display(df.iloc[-2:])\n",
    "\n",
    "# A bit of an advanced example:\n",
    "# 1:10 says \"Take the second to tenth rows (indices 1,2,3,4,5,6,7,8,9)\"\n",
    "#   :2 says \"And then skip every other row (indices 1,3,5,7,9)\"\n",
    "print(\"\\n\\nEvery second row up to the tenth row:\")\n",
    "display(df.iloc[1:10:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93ffaff6bae3fa42c1a54fad2472c72d",
     "grade": false,
     "grade_id": "cell-102464fb3c0e200a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 6\n",
    "Create a variable `groceries` which contains all the information in `df` for Broccoli, Coffee and Rice using the `.loc` property.\n",
    "\n",
    "Create a variable `odds` which contains all the odd rows (first, third, fifth, et cetera) using `.iloc` and slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c18d284b95db506445eed45179305f3",
     "grade": true,
     "grade_id": "cell-bf21a0803dc02207",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "groceries = None\n",
    "odds = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"Groceries:\")\n",
    "display(groceries)\n",
    "\n",
    "print(\"\\n\\nOdd rows:\")\n",
    "display(odds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e569f86fd71fa641e2ff6443824a987e",
     "grade": false,
     "grade_id": "cell-c95bb84e2a8d6a58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Combining row and column selection\n",
    "\n",
    "If you want to select specific rows *and* columns from a `DataFrame`, there are many ways you can do this in *Pandas*. First off, you can just combine the methods for selecting rows and columns you saw earlier, as these always return a `DataFrame` which you can just index again.\n",
    "\n",
    "Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2774badc02058533538e8245fbf6b26",
     "grade": false,
     "grade_id": "cell-888d67f62849651b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "print(\"\\nSelecting columns first, then indexing the resulting rows using loc:\")\n",
    "cols = df[['Category', 'Price']]\n",
    "res1 = cols.loc[['Carrot', 'Juice', 'Rice']]\n",
    "display(res1)\n",
    "\n",
    "\n",
    "print(\"\\nIndexing the rows using their position with iloc, then selecting the columns:\")\n",
    "rows = df.iloc[[3, 6, 9]]\n",
    "res2 = rows[['Category', 'Price']]\n",
    "display(res2)\n",
    "\n",
    "\n",
    "print(\"\\nSelecting columns first, then slices on iloc, executed on the same line:\")\n",
    "res3 = df[['Category', 'Price']].iloc[3:10:3]\n",
    "display(res3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "641abf9be7d7d51f0194c56773f6a7f3",
     "grade": false,
     "grade_id": "cell-449743f3387bce76",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that all these different methods end up with the same DataFrame! Actually any combination of row and column indexing you've seen before would work for this, of course.\n",
    "\n",
    "In addition, `loc` and `iloc` also support the option to index rows and columns together in the same operation, which is a little more efficient than first creating new Series for the full rows and then selecting from them. With these methods the row indices must always come first (as `loc` and `iloc` are row-based operations), and then optionally you can add a column index too, separated by a comma. This combined indexing also works for single indices, where you only give one index for the rows or columns position, instead of a list. Note in those cases the row or column is reduced, and the result will no longer be a DataFrame. A few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d89ba1d88bf8a2ce15773119bb53f9b9",
     "grade": false,
     "grade_id": "cell-d0e97f334570e840",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "print(\"\\nSelecting the rows with index Apple and Broccoli, and the columns Category and Stock\")\n",
    "display(df.loc[ ['Apple', 'Broccoli'], ['Category', 'Stock'] ])\n",
    "\n",
    "print(\"\\nSelecting the first and second row, and the second and fourth column:\")\n",
    "display(df.iloc[ [0, 1], [1, 3] ])\n",
    "\n",
    "print(\"\\nSelecting the Penne row and the Price column (which is just an element):\")\n",
    "display(df.loc['Penne', 'Price'])\n",
    "\n",
    "print(\"\\nSelecting only the first row, and the first and fourth column (which is a Series):\")\n",
    "display(df.iloc[0, [0, 3]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe450690bc1c98988a2eccf8e16c403d",
     "grade": false,
     "grade_id": "cell-4199c8ca146deb6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "All these different indexing methods can make *Pandas* especially confusing to newcomers, as they are all used interchangeably in explanations and example you might find online. One of the goals of this notebook is to introduce all of these properly, so you can make a bit more sense of the different options you might encounter.\n",
    "\n",
    "Below are 3 examples all using `loc` that look very similar, but do completely different things. Read the code fo the examples and try to predict what each of these will do, before actually running the cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e830c88754d5d77c02f8d604653466b9",
     "grade": false,
     "grade_id": "cell-206ca37cf5bf63af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "example1 = df.loc['Apple', 'Price']\n",
    "\n",
    "print(\"\\nExample 1:\")\n",
    "display(example1)\n",
    "\n",
    "example2 = df.loc[['Apple', 'Broccoli']]\n",
    "\n",
    "print(\"\\nExample 2:\")\n",
    "display(example2)\n",
    "\n",
    "example3 = df.loc[['Apple'], ['Price']]\n",
    "\n",
    "print(\"\\nExample 3:\")\n",
    "display(example3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "164c3bd7ad231f2efa2d87421ab45ba5",
     "grade": false,
     "grade_id": "cell-40fd2e00f3ebdbf9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 7\n",
    "\n",
    "Below are 3 exercises to test your understanding with:\n",
    "\n",
    "a) Select the Broccoli, Coffee and Rice rows from the DataFrame, while also only selecting the Category and Price columns. Save the results in `ex_7a`.\n",
    "\n",
    "b) Select the last 3 rows from the DataFrame, while also only selecting the Price and Unit columns. Save the results in `ex_7b`.\n",
    "\n",
    "c) Select the Unit and Stock for Juice. The results should be Series indexed with Unit and Stock. Save the results in `ex_7c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71bcd5e2983a1cd44b46531818b5ddc8",
     "grade": true,
     "grade_id": "cell-3194bf62f17e7236",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "ex_7a = None\n",
    "ex_7b = None\n",
    "ex_7c = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"\\n7a:\")\n",
    "display(ex_7a)\n",
    "\n",
    "print(\"\\n7b:\")\n",
    "display(ex_7b)\n",
    "\n",
    "print(\"\\n7c:\")\n",
    "display(ex_7c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6ea603ff92ac75ff00d1ef6b4895dcf",
     "grade": false,
     "grade_id": "cell-5bdde946f0f08f8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Masking\n",
    "\n",
    "The last, and very useful, method we'll cover to select data from you DataFrame is masking. Masking is another concept borrowed directly from *Numpy*, as so works almost exactly the same way in *Pandas*.\n",
    "\n",
    "Masks are used to select parts of a DataFrame where some condition is `True`. You can create a mask by using boolean operators (like  `>`, `<=` or `==`) directly on a DataFrame or Series to define the condition where the mask should be `True`. This will result a broadcasted comparison of elements on the DataFrame/Series, so will create a new DataFrame/Series containing only `True`s and `False`s. Applying a mask just takes the part(s) of your DataFrame where the mask is `True`, and leaves out the parts where it is `False`.\n",
    "\n",
    "The code below uses the Stock column to create a mask called `mask` where the Stock column is less than four, then uses it to show what items in the DataFrame are low in stock. Note that the `dtype` of the mask becomes `bool`ean and it indeed contains only `True` for the rows that have a Stock less than 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12cba7c2b5178b1f5d152241d7924fee",
     "grade": false,
     "grade_id": "cell-33cdde551f2ba831",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "mask = df['Stock'] < 4\n",
    "\n",
    "print(\"\\nMask where Stock is less than 4:\")\n",
    "display(mask)\n",
    "\n",
    "print(\"\\nUsing the mask on the DataFrame gives:\")\n",
    "display(df[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "727ef94914adaab995f63cbb09689b08",
     "grade": false,
     "grade_id": "cell-f6b6ea9d419621cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Pandas also has built-in functions to create masks. One such example is the `pd.Series.isin(values)` method. This mask is `True` whenever a element in a Series is equal to one of the elements you provided as the *list* of `values`.\n",
    "\n",
    "As an example, the code below creates a mask where the values in the 'Category' column are either 'Vegetables' or 'Fruits'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "106cd56be91cd549d14514ec35749868",
     "grade": false,
     "grade_id": "cell-aa7fc9e26b611f4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "mask = df['Category'].isin(['Vegetables', 'Fruits'])\n",
    "\n",
    "print(\"\\nThe mask where the category is either Fruits or Vegetables:\")\n",
    "display(mask)\n",
    "\n",
    "print(\"\\n\\nThe result of applying this mask on the DataFrame:\")\n",
    "display(df[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4fbff43f2c7ea0d8b982ae8e469c603",
     "grade": false,
     "grade_id": "cell-f8da8d95a65ec900",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can also use logical operations, like *logical or* `|` and the *logical and* `&`, to combine two masks element-wise. The first creates a new mask where each element is `True` if one of the masks was `True` for that element, and the second creates a new mask where each element is `True` if both the masks were `True` for that element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0164ed414691fdced16e659dc5e7c14c",
     "grade": false,
     "grade_id": "cell-9916dec14f3e357f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expensive = df['Price'] > 1\n",
    "low_stock = df['Stock'] < 4\n",
    "\n",
    "combined_mask = expensive & low_stock\n",
    "\n",
    "print(\"\\nThe combined mask for items that are both expensive and low in stock:\")\n",
    "display(combined_mask)\n",
    "\n",
    "print(\"\\nSelecting out the rows where the combined mask is True:\")\n",
    "display(df[combined_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ee699c3948266f52e22c20c0c95e33f",
     "grade": false,
     "grade_id": "cell-66a52f1ee99ee250",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 8\n",
    "\n",
    "Select the rows from the DataFrame where the Category is either Pastas or Fruits, and the Price is either below 1 or above 3. Store the result as `ex_8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1d255331181cbeca8d34f0f00b44386",
     "grade": true,
     "grade_id": "cell-1564d2813be364fc",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "ex_8 = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "display(ex_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "865aad74182c5ad9779cae727ec563da",
     "grade": false,
     "grade_id": "cell-7cab54b18c74306d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Further Reading:* The Python Data Science Handbook has a section on [data indexing and selection](https://jakevdp.github.io/PythonDataScienceHandbook/03.02-data-indexing-and-selection.html) and using [masks](https://jakevdp.github.io/PythonDataScienceHandbook/02.06-boolean-arrays-and-masks.html). The documentation on [`.iloc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html) and [`.loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) also contains more examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be8931bdbcbf78ff8eb91e738ab91b1d",
     "grade": false,
     "grade_id": "cell-c83f95894070d885",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Operating on DataFrames\n",
    "\n",
    "In the section on [`Adding and modifying data`](#Adding-and-modifying-data) you already saw that basic arithmetic operations are actually done *element-wise* by default, which is extremely useful. The general term for operations that are applied element-wise are \"Universal Functions\" (or Ufuncs) and make libraries such as NumPy and Pandas incredibly powerful, convenient and computationally efficient. These Ufuncs do not only work with basic arithmetics (`+`, `-`, `*`, `/`, etc) but also more sophisticated operations (exponential, trigonometric, logarithmic functions and many more).\n",
    "\n",
    "With all of these operations, it is important to keep track of the `index` of the Series you are using. For example, if you have a Series `a` with index `0,1,2` and a Series `b` with index `1,2,3`, the operation `c = a + b` will have index `0,1,2,3` (the union of the index of `a` and `b`). Only on indices `1` and `2` will it be able to compute a result, and on indices `0` and `3` it will automatically fill in `NaN` (\"Not a Number\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "934365e0962adbe4da3fcf158eaec1c1",
     "grade": false,
     "grade_id": "cell-6fb53e254d5d3f50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "a = pd.Series(\n",
    "    data=[5, 2, 3],\n",
    "    index=[0, 1, 2]\n",
    ")\n",
    "b = pd.Series(\n",
    "    data=[7, 3, 1],\n",
    "    index=[1, 2, 3]\n",
    ")\n",
    "\n",
    "print(\"Series a:\")\n",
    "display(a)\n",
    "\n",
    "print(\"\\n\\nSeries b:\")\n",
    "display(b)\n",
    "\n",
    "print(\"\\n\\na+b gives:\")\n",
    "display(a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5dac89a8f090ffa567cd74fc1cc32544",
     "grade": false,
     "grade_id": "cell-fccb7f1589d747ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see, the indices `1` and `2` have been added element-wise, as they occur in *both* Series, while for indices `0` and `3` no valid result could be computed, so they become `NaN`. If you want a different result for the indices that only occur once, you'll need to specify how to handle those cases with the `pd.Series.add(...)` method. Using `a.add( b )` is completely equivalent to `a + b`, but using `.add` allows you to specify a `fill_value`, which it will use whenever one of the Series is missing a value for some index.\n",
    "\n",
    "For example, we can set up a Series called `sales` with the daily sales for some products. If you want to subtract these from the 'Stock' Series in `df`, you need to specify what to do with the missing indices. In this case, we can fill these with zeros using the `sub` function and `fill_value=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7cf12cad985d0de70938ae24044b4dc",
     "grade": false,
     "grade_id": "cell-eff661e502ddf9d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "# Extract the 'Stock' column\n",
    "stock = df['Stock']\n",
    "\n",
    "print(\"Stock before sales:\")\n",
    "display(stock)\n",
    "\n",
    "# Set up a 'sales' Series\n",
    "sales = pd.Series(\n",
    "    data=[1, 3, 1, 2, 1, 2],\n",
    "    index=['Lettuce', 'Carrot', 'Tagliatelle', 'Coffee', 'Apple', 'Strawberry'],\n",
    "    dtype=int,\n",
    "    name='Sales'\n",
    ")\n",
    "\n",
    "print(\"\\n\\nSales:\")\n",
    "display(sales)\n",
    "\n",
    "print(\"\\n\\nStock after sales:\")\n",
    "display( stock.sub(sales, fill_value=0) )\n",
    "\n",
    "# See what happens if you do not specify a `fill_value` by uncommenting the following line:\n",
    "# display( stock.sub(sales) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a5c1e401b742fdc293cb4c8f0817dfd5",
     "grade": false,
     "grade_id": "cell-23e886ba6acf3ae4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 9\n",
    "\n",
    "The government has decided to stimulate eating health by removing VAT (Value Added Tax) from all fresh fruits and vegetables. As result, you'll need to lower the prices of some of your products according. You already got a list of the VAT charges per product from the owner of the store, and now just need to update the prices in the DataFrame. Make sure the prices of the other products are not affected!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ee9786b949fc80b8aa9d96f114ad9c6",
     "grade": true,
     "grade_id": "cell-e2aea1adaf09f4b3",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "fruit_veg_tax = pd.Series([0.22, 0.13, 0.12, 0.04, 0.06, 0.07, 0.31],\n",
    "    index=['Apple', 'Banana', 'Broccoli', 'Carrot', 'Eggplant', 'Lettuce', 'Strawberry']\n",
    ")\n",
    "\n",
    "print(\"\\nThe VAT charge added per fruit/vegetable:\")\n",
    "display(fruit_veg_tax)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"\\nThe DataFrame with updated prices\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "771dfe15818c1cb28348ebaa5ef72380",
     "grade": false,
     "grade_id": "cell-2102bc98e3387c35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Further Reading:* The python data science handbook on [operations in pandas](https://jakevdp.github.io/PythonDataScienceHandbook/03.03-operations-in-pandas.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83558d89745166f86448cea17ad7ea0c",
     "grade": false,
     "grade_id": "cell-45420cd61ab416e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Map\n",
    "\n",
    "Next to these built-in operations, you can also apply your own function to each value in a Series. Below is a very simple example function, that just returns the length of a string. Say you want to apply `myFunc` to each value in `series_in` and save the results in `series_out`, then you might write something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91163351fd52cbb4af609a6853d01637",
     "grade": false,
     "grade_id": "cell-195fc7b7361953a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# A very simple example function\n",
    "def myFunc(value):\n",
    "    newValue = len(value)\n",
    "    return newValue\n",
    "\n",
    "\n",
    "# Get some Series\n",
    "series_in = pd.Series([\"Hello\", \"world!\"])\n",
    "\n",
    "print(\"Input series:\")\n",
    "display(series_in)\n",
    "\n",
    "\n",
    "# Save the new results in a list for now\n",
    "series_out = []\n",
    "\n",
    "# Go through each value in the input Series\n",
    "for value in series_in:\n",
    "    # Apply your function to the value, save in output list\n",
    "    series_out.append( myFunc(value) )\n",
    "\n",
    "# Create a new series with new values\n",
    "series_out = pd.Series(series_out)\n",
    "\n",
    "\n",
    "print(\"\\n\\nOutput Series:\")\n",
    "display(series_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c83d6ad8551965f0567d27bcf1ce520f",
     "grade": false,
     "grade_id": "cell-0f0ed68e9f438ea2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "But looping through values, appending them and then creating a new Series is quite inefficient. All of this can be replaced by using the `pd.Series.map` method. You provide the name of your function (`myFunc` in this case), and Pandas will *map* each value in your Series using your function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "306783fc8129f9dcddf892d7a3415e38",
     "grade": false,
     "grade_id": "cell-949b186eb986fc76",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# A very simple example function\n",
    "def myFunc(value):\n",
    "    # Do some operations here...\n",
    "    newValue = len(value)\n",
    "    return newValue\n",
    "\n",
    "\n",
    "# Get some Series\n",
    "series_in = pd.Series([\"Hello\", \"world!\"])\n",
    "\n",
    "print(\"Input series:\")\n",
    "display(series_in)\n",
    "\n",
    "\n",
    "# Apply myFunc to each value in series_in, save the result in series_out\n",
    "series_out = series_in.map(myFunc)\n",
    "\n",
    "\n",
    "print(\"\\n\\nOutput Series:\")\n",
    "display(series_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d590a961f4ce5c0c1d4edcd38773416",
     "grade": false,
     "grade_id": "cell-5f10f61027f051d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 10\n",
    "Your boss wants to create some advertisements, and needs to replace each 'kg', 'pc' and 'gr' in the 'Unit' column with the full name. You have already written a function called `rename_units` - which replaces each occurance of 'kg', 'pc', 'gr' and 'L' with the full name - and now want to apply it efficiently to the 'Unit' column.\n",
    "\n",
    "Use the `rename_units` function defined below to `map` all the values in the series `units`. Save the results in your `df` as column 'Units - Long'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3df6dba3da0e567b4c84c18d50d96960",
     "grade": true,
     "grade_id": "cell-960c04e79f427a85",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def rename_units(units_str):\n",
    "    \"\"\"\n",
    "    Rename shorthands for units to their full name\n",
    "    such as 'gr' to 'Gram', 'pc' to 'Stucks'\n",
    "\n",
    "    Input: units_str - a string to replace units in\n",
    "    Output: A string with unit shorthands replaced with full name\n",
    "    \"\"\"\n",
    "    units_str = units_str.replace(\"gr\", \"Gram\")\n",
    "    units_str = units_str.replace(\"kg\", \"Kilogram\")\n",
    "    units_str = units_str.replace(\"pc\", \"Stuks\")\n",
    "    units_str = units_str.replace(\"L\", \"Liter\")\n",
    "    return units_str\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc0fc4d996772aeae7953abb54857772",
     "grade": false,
     "grade_id": "cell-3e5c720c6daced30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Lambda functions\n",
    "\n",
    "One thing you'll see very commonly in combination with `map` are `lambda` functions. Lamba functions are built-in to Python (so not a part of *Pandas* specifically), and can be use to quickly define functions you only want to use once, which is exactly what you want to do with a `map` most of the time.\n",
    "\n",
    "For example, let's say you want convert all the Categories to lowercase. Defining a function for this and using `map` would be a good solution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a10c38dddff8cda9c46d39702113c23",
     "grade": false,
     "grade_id": "cell-529a175d8209ab57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def lowercase(x):\n",
    "    return x.lower()\n",
    "\n",
    "\n",
    "df = get_df()\n",
    "\n",
    "df['Category'] = df['Category'].map(lowercase)\n",
    "\n",
    "print(\"\\nThe Category column replaced by the lowercase version:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0dad1a272b868c269d62faa46c25476",
     "grade": false,
     "grade_id": "cell-74365eeb204a074c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "An even more compact solution would be to use a `lambda` function here. A lambda function starts with the word `lambda`, followed by a space, the argument of your function (the example below uses `x`) and a colon (`:`). After that you can write a single line of code for the function, which will define what the function *returns*.\n",
    "\n",
    "This is just a shorter way to write a function, where you don't need give it a name, don't need to write `return` and can define it on the same line. The example above can be replaced by the following using a `lamdba` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6c4dee333fb7a4d572ecce4debcd73b",
     "grade": false,
     "grade_id": "cell-85e710146877f083",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "df['Category'] = df['Category'].map(lambda x: x.lower())\n",
    "\n",
    "print(\"\\nThe Category column replaced by the lowercase version:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57cc066e062bf826dcd4630a0dafcc37",
     "grade": false,
     "grade_id": "cell-7ec000fe5c40f663",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Further Reading:* More about [lambda statements](https://www.dataquest.io/blog/tutorial-lambda-functions-in-python/), including examples with and without the use of Pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ee3bb6474a448a2ddce1e73f983b5b1",
     "grade": false,
     "grade_id": "cell-be645dbacb3a3378",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Sorting values\n",
    "\n",
    "Sorting your DataFrame or Series is also a useful and common operation. This is as easy as providing a column to sort on, and *Pandas* will do the rest. By default this will sort the rows of the DataFrame in ascending order (lowest to highest), but you can change this by setting the optional `ascending` parameter to `False`. Note that strings are automatically sorted in alphabetical order too.\n",
    "\n",
    "The code below will sort the DataFrame by the 'Category' column in ascending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "975bd714569e34f0f102a035c9b25ff7",
     "grade": false,
     "grade_id": "cell-cf28ee46bbab8127",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "sorted_categories = df.sort_values(by='Category')\n",
    "\n",
    "display(sorted_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2233d2bd48e859849cb1a15b9b54990f",
     "grade": false,
     "grade_id": "cell-f55b1750b3e511a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 11\n",
    "\n",
    "Sort the `df` by 'Price' in descending order and store the result in `df_sorted`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1ae0907746e02e05fb8f6aff886f202",
     "grade": false,
     "grade_id": "cell-b59be63454fb748c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "df_sorted = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "display(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f0df1116450eca1fa66f2e3cebcb957",
     "grade": true,
     "grade_id": "cell-2139c3db35f98ea7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_11(df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ba034d42d48b9b40850a7a76ac3e305",
     "grade": false,
     "grade_id": "cell-d696be4eb24ccbb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Another useful method is sorting by multiple columns: simply replace the `by=...` argument with a list of column names (`by=['col1', 'col2', ...]`). Similarly, you can replace the `ascending=...` argument with a list with `True` or `False` values (`ascending=[True, False, ...]`) of the same length, which indictates for each of the corresponding columns whether they should be sorted in ascending order or not.\n",
    "\n",
    "Note that order of the columns in the `by` list matter, as the DataFrame will be sorted by the first column first, and so on. The code below first sorts by the 'Category' column (in ascending order). If multiple rows have the same category, it will then sort these by the 'Stock' column (in descending order):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86f333b36a5f36cd6b6a8cbc863ef971",
     "grade": false,
     "grade_id": "cell-95a8d7c99b081aa5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "display(df.sort_values(by=['Category', 'Stock'], ascending=[True, False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ecfedf5f7d451d3e23b79fb410775144",
     "grade": false,
     "grade_id": "cell-c5c4d9adaa421446",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 12\n",
    "\n",
    "Sort the `df` by category, then price, both in descending order, store the result in `df_sorted2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "389532d149d08e5586c97ea25e50586d",
     "grade": true,
     "grade_id": "cell-2fc63fa3120a9617",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "df_sorted2 = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "display(df_sorted2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95fb851efb7feab174af444a97427205",
     "grade": false,
     "grade_id": "cell-c3ed1165fdf9b8ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Handling missing values\n",
    "\n",
    "In the section on [operations](#operating-on-dataframes) we already encountered some `NaN` values. Knowing how to deal with missing values is a great skill when working messy datasets (which most datasets are, in practice).\n",
    "\n",
    "For this exercise we will use a different dataset: For the most popular products in the store (Carrots, Apples, Coffee and Lettuce), your boss has kept a registry of the stock over time. In this case, the products are the columns, and each row is indexed by a date. The values you see is the stock at the start of each week (the market gets restocked on the first of each month).\n",
    "\n",
    "Unfortunately, some values were illegible and are replaced with `NaN` values. In this section you will see some tools that can help you deal with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e27c2dfcc95b06da512b74d2e3bb751",
     "grade": false,
     "grade_id": "cell-7ba2510a80187645",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "stock_df = get_stocks()\n",
    "\n",
    "display(stock_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d1d6eef32116f4d931292750c4e6dbb",
     "grade": false,
     "grade_id": "cell-ec8bd6bf6a303048",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The most simple method of dealing with `NaN` values is by removing them. This can be done using the `pd.DataFrame.dropna(...)` method. By default, it will remove any row that has any `NaN` on it. You can change this to drop any _column_ that has at least one `NaN` value by passing `axis=1`. If you want to drop a row/column if it is _completely_ filled with `NaN` values, you can pass `how='all'`.\n",
    "\n",
    "Below is a code example that uses `dropna` with `axis=0` and `how=any` (which are also the default options) to remove the rows containing `NaN`. You can make a new cell where you copy this example and can play around with different combinations of argument. With each combination of arguments you test, try to predict how many rows and columns you expect to see before running the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b357efb2cfd0058d586509890f9c22f7",
     "grade": false,
     "grade_id": "cell-35f6147a89be0b95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "stock_df = get_stocks()\n",
    "\n",
    "# Drop rows/columns that contain NaN values\n",
    "# axis=0 -> drop rows (default)\n",
    "#      1 -> drop columns\n",
    "# how='any' -> if that row/column contains at least one NaN value (default)\n",
    "#     'all' -> if that row/column contains only NaN values\n",
    "cleaned_df = stock_df.dropna(axis=0, how='any')\n",
    "\n",
    "display(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "452ca2235df979ec208d00690a2961ee",
     "grade": false,
     "grade_id": "cell-0dec806cb829f7b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The above example shows that, no matter how you deal with discarding `NaN` values, you throw away some valuable data in the process.\n",
    "\n",
    "Instead, you can try to replace these missing values with some _approximation_ or guess of what these values could have been. Doing this in a sophisticated way is its own field of research (called Regression, which is part of Machine Learning), but for now we will just replace each `NaN` with a constant value (i.e. the same value everywhere).\n",
    "\n",
    "Filling values can be done using the `pd.DataFrame.fillna(...)` method. For example, you can specify some `value` you want to fill with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de3d288be03d9549e153bc35a2f5f52b",
     "grade": false,
     "grade_id": "cell-01b4212aa81f3b7a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "stock_df = get_stocks()\n",
    "\n",
    "display(stock_df.fillna(value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f5bd19a5180b4c64dbf129bd5f01515",
     "grade": false,
     "grade_id": "cell-9f67c2f0d9482a3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Using the same constant value for each column might not be the best approach: there seem to be many more Carrots in stock than Coffee. It would be better if you use some constant value for one column, and another value for another column.\n",
    "\n",
    "You can do this by passing a 'mapping' in the `value` argument, which gives a value to use for each column in the dataframe. A `dict`ionary is a type of mapping, which maps the keys of that dictionary to the corresponding values. The example below uses Carrot, Apple and Coffee as a key, each with their own value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b8e13a5705b59be41d4217eb70b4f2e",
     "grade": false,
     "grade_id": "cell-896383f9e32b0937",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "stock_df = get_stocks()\n",
    "\n",
    "# Create a dictionary (a type of mapping)\n",
    "mapping = {\n",
    "    'Carrot': 15,\n",
    "    'Apple': 10,\n",
    "    'Coffee': 2\n",
    "}\n",
    "\n",
    "display(stock_df.fillna(value=mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c70bbd23d7f34ad61fd92d1c95a0f3d8",
     "grade": false,
     "grade_id": "cell-2c45f10fa1010cc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 13\n",
    "\n",
    "A Series is another example of a mapping, where map the indices to values. Use the [pd.DataFrame.mean()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html) function to compute the average stock for every product. The result should be a Series and stored in `product_means`.\n",
    "\n",
    "Next, use this mapping to replace the missing values in `stock_df` for each column with the mean of that column. Store the result in `cleaned_stocks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4ed09dbd687fa612677345d68aa1c58",
     "grade": true,
     "grade_id": "cell-ab695528afc5e521",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "stock_df = get_stocks()\n",
    "\n",
    "product_means = None\n",
    "cleaned_stocks = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"The average stock of per product:\")\n",
    "display(product_means)\n",
    "\n",
    "print(\"\\n\\nUsing this as constant fill for each column gives:\")\n",
    "display(cleaned_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb4090cade85f928d101a0d8cc72fdfd",
     "grade": false,
     "grade_id": "cell-92fc048ef25d339a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Further Reading:* in the python data science handbook on [handling missing data](https://jakevdp.github.io/PythonDataScienceHandbook/03.04-missing-values.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a64ad36a112f6c5eed3e091f5bb5dc7",
     "grade": false,
     "grade_id": "cell-790839ca5880e300",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Grouping\n",
    "\n",
    "Categorical variables (such as the 'Category' column in our example dataset) can also be used to group data together. In doing this, you combine one or more rows from your original DataFrame into a row in the grouped DataFrame. You will then need to specify how these rows get combined (also called 'aggregating'), as multiple rows will need to be reduced to one row per Category.\n",
    "\n",
    "First, you can group a DataFrame using the `pd.DataFrame.groupby` method and specifying what column you want to group on. This gives something called a `DataFrameGroupBy`, which is special intermediate `groupby` object. The groupby can then be completed by using an aggregate function on the `DataFrameGroupBy`. This will return a regular `DataFrame` again, with its rows reduced as specified by the aggregate function.\n",
    "\n",
    "You've already seen some the possible aggregate function for numerical values throughout this notebook. These are functions like `.sum()`, `.max()`, `.min()`, `.mean()` and `.median()`, which combine values by computing, for example, the maximum value in each column. With a `groupby` these functions then get applied to all the *other* columns than were not grouped on, resulting in a new DataFrame with one row for each group. Note that is not possible to apply these functions on *nonnumerical* columns (like the Units column), so trying this will result in an error. You can pass the optional `numeric_only=True` argument to the aggregate functions to tell *Pandas* explicitly to just drop those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0498e28f2f3ae732ca78acf6dbaff18",
     "grade": false,
     "grade_id": "cell-2cffd99d8b31a855",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "grouped_df = df.groupby('Category')\n",
    "\n",
    "print(\"\\nIntermediate groupby object, which isn't a real DataFrame:\")\n",
    "display(grouped_df)\n",
    "\n",
    "print(\"\\nHowever, we can access each group separately, which are DataFrames:\")\n",
    "for (group_name, group_df) in grouped_df:\n",
    "    print('\\n'+ group_name +':')\n",
    "    display(group_df)\n",
    "\n",
    "\n",
    "category_means = grouped_df.mean(numeric_only=True)\n",
    "\n",
    "print(\"\\n\\n\\nComputing the mean per group for each column:\")\n",
    "display(category_means)\n",
    "\n",
    "# Note this is usually how this is used, with both function calls on the same line\n",
    "# so without storing the intermediate groupby object seperately\n",
    "category_max = df.groupby('Category').max(numeric_only=True)\n",
    "\n",
    "print(\"\\nComputing the maximum per group for each column:\")\n",
    "display(category_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a1d0d8f4e3016ccaa46be5c97b95909",
     "grade": false,
     "grade_id": "cell-f6a26c0424a8884f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see, the result of these groupby and aggregates is a new DataFrame containing the combined data. In the mean DataFrame you can, for example, see that average Stock of all the Breakfast items is $6.5$. And, in the max DataFrame you can see that the Fruit with the highest Price costs $3.49$.\n",
    "\n",
    "There are also some aggregate functions that work on both numerical and categorical columns:\n",
    "\n",
    "- `grouped_df.count()` will count the number of rows in that group, excluding `NaN`s.\n",
    "- `grouped_df.nunique()` counts the number of unique values in each group for each column.\n",
    "- `grouped_df.first()` gives the elements of the first of the grouped rows. Similarly, `.last()` gives the last.\n",
    "- `grouped_df.head(n)` will include (up to) the first `n` rows in that group. Similarly, `.tail(n)` gives the last `n` rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b5f4fd2a6d8beddb905aad9857e1b46",
     "grade": false,
     "grade_id": "cell-43edfc89c41e66aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "print(\"\\nThe number of unique values in each group:\")\n",
    "display(df.groupby('Category').nunique())\n",
    "\n",
    "print(\"\\nThe first value in each group:\")\n",
    "display(df.groupby('Category').first())\n",
    "\n",
    "print(\"\\nKeeping (up to) the first 2 rows per group:\")\n",
    "display(df.groupby('Category').head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5dca91d20ba5ded7ae2a2c76acaccfe",
     "grade": false,
     "grade_id": "cell-b276d33af0f7d5d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Like regular `DataFrames`, you can select one or more columns from a `DataFrameGroupBy` using the column names. Remember that, as when indexing columns, a single column will always return a Series, and a list of columns (even a list of 1 column) returns a DataFrame!\n",
    "\n",
    "The example below computes the minimum Stock per Category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02181c532b18c11672b849d876349c20",
     "grade": false,
     "grade_id": "cell-896aad56b07bfe15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "\n",
    "grouped_df = df.groupby('Category')\n",
    "\n",
    "minimum_stock = grouped_df['Stock'].min()\n",
    "\n",
    "print(\"\\nThe minimum values in the Stock column, per Category:\")\n",
    "# Passing just 'Stock' gives a Series, from which we compute the min\n",
    "display(minimum_stock)\n",
    "\n",
    "unique_price_unit = grouped_df[['Price', 'Unit']].nunique()\n",
    "\n",
    "print(\"\\nThe number of unique values in the 'Price' and 'Unit' column, per category:\")\n",
    "# Passing multiple columns gives a DataFrame; from which we compute the n-unique\n",
    "display(unique_price_unit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1c6ba285f9e390ac8062b3a63a936a7",
     "grade": false,
     "grade_id": "cell-e96005986d8689b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 14\n",
    "\n",
    "Use the groupby indexing to compute the mean for the Price and Stock columns per Category. Your result should be the same as the earlier mean example, but you cannot use `numeric_only=True` here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cd0f17d8ce9fd9b351af480bd351526",
     "grade": false,
     "grade_id": "cell-ab80c0837e94763e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "mean_per_cat = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "display(mean_per_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc5d328c20b380376aa18e0601b87d6e",
     "grade": true,
     "grade_id": "cell-250edb7589226daa",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_14(mean_per_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1305d0dab29c331a71a49d0109c81f5",
     "grade": false,
     "grade_id": "cell-a75d6884285d4625",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Pandas supports many more methods of aggregating data, which you can use through the `grouped_df.agg()` method. Rather than 'just' computing the mean, you can give a list of methods to aggregate the groups in your DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01818b47e8c70dd497108cc8eb9f74b2",
     "grade": false,
     "grade_id": "cell-401d3864a0b59fa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "grouped_df = df.groupby('Category')\n",
    "\n",
    "# For each column, compute the number of unique values and the number of rows per category\n",
    "display(\n",
    "    grouped_df.agg(['nunique', 'count'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc61d2e73801215fec603f4596eae365",
     "grade": false,
     "grade_id": "cell-6afd8c7c35b44f46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 15\n",
    "\n",
    "For this last assignment you will need to compute some statistics on the Prices for each Category.\n",
    "\n",
    "Create a new DataFrame called `price_stats` that contains the number of items in each category, together with the maximum, minimum and mean Price in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fb92a64319135a1b6bd6c62810e56b9",
     "grade": false,
     "grade_id": "cell-a3e89b0f62b3dc48",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "price_stats = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "display(price_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b946c2020b90901f66373eda0c4660ff",
     "grade": true,
     "grade_id": "cell-8958a33e42b9b70d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_15(price_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa1affbbdfd3af624f7781ce305f96e6",
     "grade": false,
     "grade_id": "cell-a9e7b7d8165cb19d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Further Reading:* On [grouping data](https://jakevdp.github.io/PythonDataScienceHandbook/03.08-aggregation-and-grouping.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
